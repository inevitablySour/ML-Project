{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c90d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data\\rider_infos.csv\n",
      "Loaded data\\rider_urls.csv\n",
      "Loaded data\\results\\Results2012CatWT.csv\n",
      "Loaded data\\results\\Results2014CatWT.csv\n",
      "Loaded data\\results\\Results2015CatWT.csv\n",
      "Loaded data\\results\\Results2016CatWT.csv\n",
      "Loaded data\\results\\Results2017CatWT.csv\n",
      "Loaded data\\results\\Results2018CatWT.csv\n",
      "Loaded data\\results\\Results2019CatWT.csv\n",
      "Loaded data\\results\\Results2020CatWT.csv\n",
      "Loaded data\\results\\Results2021CatWT.csv\n",
      "Loaded data\\team_urls\\team_urls_2012.csv\n",
      "Loaded data\\team_urls\\team_urls_2013.csv\n",
      "Loaded data\\team_urls\\team_urls_2014.csv\n",
      "Loaded data\\team_urls\\team_urls_2015.csv\n",
      "Loaded data\\team_urls\\team_urls_2016.csv\n",
      "Loaded data\\team_urls\\team_urls_2017.csv\n",
      "Loaded data\\team_urls\\team_urls_2018.csv\n",
      "Loaded data\\team_urls\\team_urls_2019.csv\n",
      "Data summary has been written to data_summary.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def summarize_dataframe(df, name):\n",
    "    \"\"\"\n",
    "    Generates a detailed markdown summary of a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    summary = f\"### Data Summary: {name}\\n\\n\"\n",
    "    \n",
    "    # Check if DataFrame is empty\n",
    "    if df.empty:\n",
    "        summary += \"The DataFrame is empty.\\n\\n\"\n",
    "        return summary\n",
    "\n",
    "    # 1. Overall Shape\n",
    "    summary += f\"**Shape:** {df.shape[0]} rows, {df.shape[1]} columns.\\n\\n\"\n",
    "\n",
    "    # 2. Column Information\n",
    "    summary += \"**Columns and Data Types:**\\n\"\n",
    "    for col, dtype in df.dtypes.items():\n",
    "        summary += f\"- `{col}`: {dtype}\\n\"\n",
    "    summary += \"\\n\"\n",
    "\n",
    "    # 3. Basic Statistics\n",
    "    summary += \"**Basic Statistics (for numeric columns):**\\n\"\n",
    "    summary += \"```\\n\"\n",
    "    summary += df.describe(include=['number']).to_string()\n",
    "    summary += \"\\n```\\n\\n\"\n",
    "\n",
    "    # 4. Unique Values and Top Values for non-numeric columns\n",
    "    summary += \"**Top values and unique counts (for categorical/object columns):**\\n\"\n",
    "    for col in df.select_dtypes(exclude=['number']).columns:\n",
    "        unique_count = df[col].nunique()\n",
    "        summary += f\"- `{col}` (unique values: {unique_count}):\\n\"\n",
    "        # Get the top 5 most frequent values\n",
    "        top_values = df[col].value_counts().head(5).to_dict()\n",
    "        for value, count in top_values.items():\n",
    "            summary += f\"  - `{value}`: {count} occurrences\\n\"\n",
    "        summary += \"\\n\"\n",
    "    \n",
    "    # 5. Sample Data\n",
    "    summary += \"**Sample Data (First 5 rows):**\\n\"\n",
    "    summary += \"```\\n\"\n",
    "    summary += df.head().to_markdown(index=False)\n",
    "    summary += \"\\n```\\n\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process data and generate the summary file.\n",
    "    \"\"\"\n",
    "    output_filename = \"data_summary.md\"\n",
    "    \n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Project Data Summary\\n\\n\")\n",
    "        f.write(\"This document contains a summary of the project data, generated to provide context for an LLM. \"\n",
    "                \"The original data is in a SQLite database and several CSV files.\\n\\n\")\n",
    "        \n",
    "        # --- Process SQL File ---\n",
    "        try:\n",
    "            db_file = 'cycling_big.db'\n",
    "            if os.path.exists(db_file):\n",
    "                f.write(\"## SQL Database (`cycling_big.db`) Overview\\n\\n\")\n",
    "                conn = sqlite3.connect(db_file)\n",
    "                cursor = conn.cursor()\n",
    "                \n",
    "                # Get table names\n",
    "                cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "                tables = cursor.fetchall()\n",
    "                if not tables:\n",
    "                    f.write(\"No tables found in the database.\\n\\n\")\n",
    "                else:\n",
    "                    f.write(f\"Found the following tables: {', '.join([t[0] for t in tables])}.\\n\\n\")\n",
    "                    # Use the correct table name\n",
    "                    df_sql = pd.read_sql_query(\"SELECT * FROM race_results;\", conn)\n",
    "                    f.write(summarize_dataframe(df_sql, \"SQL Table 'race_results'\"))\n",
    "\n",
    "                conn.close()\n",
    "            else:\n",
    "                f.write(\"### SQL Database Not Found\\n\\n`cycling_big.db` was not found. Skipping SQL summary.\\n\\n\")\n",
    "        except Exception as e:\n",
    "            f.write(f\"### Error Processing SQL File\\n\\nAn error occurred: {e}\\n\\n\")\n",
    "\n",
    "        # --- Process CSV Files ---\n",
    "        try:\n",
    "            # Search for all CSVs in data/ and subfolders\n",
    "            csv_files = glob.glob('data/**/*.csv', recursive=True)\n",
    "            if csv_files:\n",
    "                f.write(\"## CSV Files Overview\\n\\n\")\n",
    "                f.write(\"Combining all CSV files into a single dataset for analysis.\\n\\n\")\n",
    "                \n",
    "                all_csvs = []\n",
    "                for filename in csv_files:\n",
    "                    try:\n",
    "                        df_temp = pd.read_csv(filename, encoding='utf-8')\n",
    "                        all_csvs.append(df_temp)\n",
    "                        print(f\"Loaded {filename}\")\n",
    "                    except Exception as csv_e:\n",
    "                        print(f\"Failed to load {filename}: {csv_e}\")\n",
    "                        \n",
    "                if all_csvs:\n",
    "                    df_csv_combined = pd.concat(all_csvs, ignore_index=True)\n",
    "                    f.write(summarize_dataframe(df_csv_combined, \"Combined CSV Data\"))\n",
    "                else:\n",
    "                    f.write(\"No CSV files were successfully loaded.\\n\\n\")\n",
    "            else:\n",
    "                f.write(\"### CSV Files Not Found\\n\\nNo CSV files found in the data directory. Skipping CSV summary.\\n\\n\")\n",
    "        except Exception as e:\n",
    "            f.write(f\"### Error Processing CSV Files\\n\\nAn error occurred: {e}\\n\\n\")\n",
    "\n",
    "    print(f\"Data summary has been written to {output_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
